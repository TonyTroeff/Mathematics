{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Какво представлява производната?\n",
    "Производна на функцията $f(x)$ може да бъде дефинирана по следния начин:\n",
    "\n",
    "$$\n",
    "f'(x) = \\lim _{\\Delta x \\to 0} \\frac {f(x + \\Delta x) - f(x)} {\\Delta x}\n",
    "$$\n",
    "\n",
    "### Приближения на производна\n",
    "Тази дефиниция не може да се реализира в компютърната аритметика, тъй като паметта на всеки компютър е ограничена и това налага определени лимитации от гледна точка на броя значещи цифри след десетичната запетая, с които се представя дадено реално число. Следователно ние можем да направим следното приближение:\n",
    "\n",
    "$$\n",
    "f'(x) \\approx \\frac {f(x + \\Delta x) - f(x)} {\\Delta x}\n",
    "$$\n",
    "\n",
    "Ако формално положим $\\Delta x = - \\Delta y$, то ще получим друго подобно приближение:\n",
    "$$\n",
    "f'(x) \\approx \\frac {f(x + \\Delta x) - f(x)} {\\Delta x} = \\frac {f(x - \\Delta y) - f(x)} {- \\Delta y} = \\frac {f(x) - f(x - \\Delta y)} {\\Delta y}\n",
    "$$\n",
    "$$\n",
    "\\implies f'(x) \\approx \\frac {f(x) - f(x - \\Delta x)} {\\Delta x}\n",
    "$$\n",
    "\n",
    "Ако съберем двата израза ще получим:\n",
    "$$\n",
    "f'(x) \\approx \\frac {f(x + \\Delta x) - f(x - \\Delta x)} {2 \\Delta x}\n",
    "$$\n",
    "\n",
    "### Визуализация на методите за приближение на производна\n",
    "В следващите няколко графики може да видите разликите в точността и да сравните грешката, която се допуска в следствие на направеното приближение, в зависимост от използвания метод и стойността на $\\Delta x$. Ще работим с функцията $f(x) = e^x$, чиято производна има същия вид ($f'(x) = e^x$)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:33.808890800Z",
     "start_time": "2023-08-08T19:31:31.815238600Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from scipy.misc import derivative\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "nodes = np.arange(-5, 5, 0.01)\n",
    "\n",
    "\n",
    "def f1(num: int) -> float:\n",
    "    return np.exp(num)\n",
    "\n",
    "\n",
    "def approximated_derivation_1(num: float, delta: float) -> float:\n",
    "    return (np.exp(num + delta) - np.exp(num)) / delta\n",
    "\n",
    "\n",
    "def approximated_derivation_2(num: float, delta: float) -> float:\n",
    "    return (np.exp(num) - np.exp(num - delta)) / delta\n",
    "\n",
    "\n",
    "def approximated_derivation_3(num: float, delta: float) -> float:\n",
    "    return (np.exp(num + delta) - np.exp(num - delta)) / (2 * delta)\n",
    "\n",
    "\n",
    "def print_derivation_info(deltas: List[int], derivations: List[Callable[[float, float], float]]) -> None:\n",
    "    for i in range(len(derivations)):\n",
    "        current_derivation = derivations[i]\n",
    "\n",
    "        for j in range(len(deltas)):\n",
    "            current_delta = deltas[j]\n",
    "\n",
    "            plt.title(f'Approximated derivation #{i + 1} with delta {current_delta}')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel(\"f'(x)\")\n",
    "            plt.plot(nodes, [f1(p) for p in nodes], nodes, [current_derivation(p, current_delta) for p in nodes], 'r')\n",
    "            plt.savefig(f\"plots/approx_deriv_{i + 1}_{j + 1}.png\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "all_deltas = [0.5, 10 ** -3, 10 ** -15]\n",
    "all_derivations = [approximated_derivation_1, approximated_derivation_2, approximated_derivation_3]\n",
    "print_derivation_info(all_deltas, all_derivations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:35.090220100Z",
     "start_time": "2023-08-08T19:31:33.810906300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Approximated derivation #1 with delta 0.5](./plots/approx_deriv_1_1.png)\n",
    "![Approximated derivation #1 with delta 0.001](./plots/approx_deriv_1_2.png)\n",
    "![Approximated derivation #1 with delta 1e-15](./plots/approx_deriv_1_3.png)\n",
    "![Approximated derivation #2 with delta 0.5](./plots/approx_deriv_2_1.png)\n",
    "![Approximated derivation #2 with delta 0.001](./plots/approx_deriv_2_2.png)\n",
    "![Approximated derivation #2 with delta 1e-15](./plots/approx_deriv_2_3.png)\n",
    "![Approximated derivation #3 with delta 0.5](./plots/approx_deriv_3_1.png)\n",
    "![Approximated derivation #3 with delta 0.001](./plots/approx_deriv_3_2.png)\n",
    "![Approximated derivation #3 with delta 1e-15](./plots/approx_deriv_3_3.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Анализиране на резултатите\n",
    "\n",
    "От дефиницията за производна следва, че при намаляване на $\\Delta x$ приближението, което получаваме, трябва да бъде по-добро (от дефиницията имаме $\\Delta x \\to 0$). И наистина - намаляването на грешката се вижда ясно в първите две графики за всеки един от методите на приближение на производната, които сме използвали. При $\\Delta x = 10^{-15}$ обаче получената апроксимация не е добра.\n",
    "\n",
    "Този експеримент нагледно показва това, което бе описано по-рано - тъй като реалните числа в паметта на компютъра се представят с ограничен брой значещи цифри, грешката първоначално ще намалява при намаляване на стъпката, но когато бъде достигнат максимума на машинната точност (и следователно намаляването на стъпката няма повече да подобрява точността на същата тази апроксимация), грешката ще започне да расте заради увеличаването броя на операциите. Това е причината за появата на \"шума\" на третата графика за всеки един от методите на приближение на производната, които сме използвали.\n",
    "\n",
    "# Какво представлява численото диференциране?\n",
    "Численото диференциране ни помага да решаваме практически задачи от този вид: _\"Да се намери производна на функцията $f$ в определена точка, като стойностите на функцията са известни само в краен брой точки.\"_ Също така техниките на численото диференциране са приложими и за функции със сложен аналитичен характер, за които не е оправдано точното пресмятане на производна.\n",
    "\n",
    "Обикновено решението на подобни задачи представлява намирането на производна на някоя приближаваща функция (като за целта могат да бъдат използвани и интерполационните полиноми. Това, което трябва да се вземе предвид обаче, е, че дори малки изменения на приближаващата функция могат да доведат до по-големи изменения в производната. Нека разгледаме конкретен пример:\n",
    "\n",
    "$$\n",
    "f(x) - P(x) = -10^{-5}\\sin(mx)\n",
    "$$\n",
    "\n",
    "Тук отклонението на приближаващия полином $P(x)$ спрямо функцията $f(x)$ е $R(x) = -10^{-5}\\sin(mx)$. Очевидно е, че $|R(x)| \\leq 10^{-5}$. Нека обаче да видим какво ще се случи, ако диференцираме двете части на това уравнение:\n",
    "\n",
    "$$\n",
    "f'(x)-P'(x) = -m10^{-5}\\cos(mx)\n",
    "$$\n",
    "\n",
    "Този път ясно се вижда, че грешката $R'(x) = -m10^{-5}\\cos(mx)$ може да бъде произволно голяма в зависимост от избраната стойност за параметъра $m$. Следва да заключим, че задачата за числено диференциране не е устойчива.\n",
    "\n",
    "### Числено диференциране чрез _Интерполационния полином на Нютон_\n",
    "\n",
    "Нека въведем следните означения:\n",
    "$$\n",
    "\\omega_n(x) = (x - x_0)(x - x_1)\\dots(x - x_n)\n",
    "$$\n",
    "$$\n",
    "f_{[x_i,x_{i+1},\\dots,x_{i+k+1}]} = \\frac {f_{[x_{i+1},x_{i+2},\\dots,x_{i+k+1}]} - f_{[x_i,x_{i+1},\\dots,x_{i+k}]}} {x_{i+k+1}-x_{i}}\n",
    "$$\n",
    "\n",
    "Производната на функцията $\\omega_n$ има едно чудесно свойство, което ще използваме в някои означения по-напред:\n",
    "$$\n",
    "\\omega_n'(x) = (x - x_1)(x - x_2)\\dots(x - x_n) + (x - x_0)(x - x_2)\\dots(x - x_n) + \\dots + (x - x_0)(x - x_1)\\dots(x - x_{n-1}) = \\sum_{i=0}^{n} \\prod_{j \\neq i}^{n} (x - x_j)\n",
    "$$\n",
    "$$\n",
    "\\omega_n'(x_k) = (x_k - x_0)(x_k - x_1)\\dots(x_k - x_{k-1})(x_k - x_{k+1})\\dots(x_k - x_n)\n",
    "$$\n",
    "\n",
    "Тогава от формулата за представяне на грешка с разделена разлика получаваме:\n",
    "$$\n",
    "f(x) = N_n(f;x) + f_{[x_0,x_1,\\dots,x_n,x]}\\omega_n(x)\n",
    "$$\n",
    "$$\n",
    "f'(x) = N_n'(f;x) + \\frac {df_{[x_0,x_1,\\dots,x_n,x]}} {dx} \\omega_n(x) + f_{[x_0,x_1,\\dots,x_n,x]} \\omega_n'(x)\n",
    "$$\n",
    "\n",
    "От дефиницията за производна знаем, че:\n",
    "$$\n",
    "\\frac {df_{[x_0,x_1,\\dots,x_n,x]}} {dx} = \\lim_{\\Delta x \\to 0} \\frac {f_{[x_0,x_1,\\dots,x_n,x+\\Delta x]} - f_{[x_0,x_1,\\dots,x_n,x]}} {\\Delta x}\n",
    "$$\n",
    "\n",
    "За да продължим с по-нататъшното решение на този израз, е необходимо да отбележим едно свойство на разделените разлики, а именно - симетричността им. Ако имаме пермутацията $\\sigma : {0,\\dots,n} \\rightarrow {0,\\dots,n}$, то $f_{[x_0,x_1,\\dots,x_n]} = f_{[x_{\\sigma(0)},x_{\\sigma(1)},\\dots,x_{\\sigma(n)}]}$. Сега можем да се върнем към предишния израз:\n",
    "$$\n",
    "\\lim_{\\Delta x \\to 0} \\frac {f_{[x_0,x_1,\\dots,x_n,x+\\Delta x]} - f_{[x_0,x_1,\\dots,x_n,x]}} {\\Delta x} = \\lim_{\\Delta x \\to 0} f_{[x_0,x_1,\\dots,x_n,x,x + \\Delta x]} = f_{[x_0,x_1,\\dots,x_n,x,x]}\n",
    "$$\n",
    "\n",
    "След като знаем как се диференцират разделени разлики, нека се върнем обратно към изчисляването на производната за $f$:\n",
    "$$\n",
    "f'(x) = N_n'(f;x) + f_{[x_0,x_1,\\dots,x_n,x,x]} \\omega_n(x) + f_{[x_0,x_1,\\dots,x_n,x]} \\omega_n'(x)\n",
    "$$\n",
    "\n",
    "Освен това, ако $f \\in C^{n+2}[a,b], a \\le x_o < x_1 < \\dots < x_n \\le b, x \\in [a,b]$, то тогава можем да опростим записа, като представим разделената разлика чрез производна на $f$ в дадена точка:\n",
    "$$\n",
    "f_{[x_0,x_1,\\dots,x_k]} = \\frac {f^{(k)}(\\xi)} {k!}\n",
    "$$\n",
    "$$\n",
    "\\implies f'(x) = N_n'(f;x) + \\frac {f^{(n+2)}(\\xi)} {(n+2)!} \\omega_n(x) + \\frac {f^{(n+1)}(\\eta)} {(n+1)!} \\omega_n'(x),\n",
    "$$\n",
    "където $\\xi$ и $\\eta$ са точки от интервала $(a, b)$.\n",
    "\n",
    "От това уравнение можем да заключим, че грешката при приближаване на $f'(x)$ с $N_n'(f;x)$ е:\n",
    "$$\n",
    "R'(x) = \\frac {f^{(n+2)}(\\xi)} {(n+2)!} \\omega_n(x) + \\frac {f^{(n+1)}(\\eta)} {(n+1)!} \\omega_n'(x)\n",
    "$$\n",
    "\n",
    "Ако направим следните означение - $M_{n+2} = max_{x \\in [a,b]}|f^{(n+2)}(x)|$ и $M_{n+1} = max_{x \\in [a,b]}|f^{(n+1)}(x)|$, окончателно получаваме:\n",
    "$$\n",
    "|R'(x)| = \\frac {|f^{(n+2)}(\\xi)|} {(n+2)!} |\\omega_n(x)| + \\frac {|f^{(n+1)}(\\eta)|} {(n+1)!} |\\omega_n'(x)| \\le \\frac {M_{n+2}} {(n + 2)!} |\\omega_n(x)| + \\frac {M_{n+1}} {(n + 1)!} |\\omega_n'(x)|\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Формули за производна на _Интерполационния полином на Нютон_\n",
    "\n",
    "$$\n",
    "N_n(f; x) = f(x_0) + f_{[x_0, x_1]}(x - x_0) + f_{[x_0, x_1, x_2]}(x - x_0)(x - x_1) + \\dots + f_{[x_0, x_1, \\dots, x_n]}(x - x_0)(x - x_1) \\dots (x - x_{n-1})\n",
    "$$\n",
    "$$\n",
    "N_n'(f; x) = f_{[x_0, x_1]} + f_{[x_0, x_1, x_2]}[(x - x_0) + (x - x_1)] + f_{[x_0, x_1, x_2, x_3]}[(x - x_0)(x - x_1) + (x - x_0)(x - x_2) + (x - x_1)(x - x_2)] + \\dots + f_{[x_0, x_1, \\dots, x_n]} \\sum_{i=0}^{n-1} \\prod_{j \\neq i}^{n-1} (x - x_j)\n",
    "$$\n",
    "\n",
    "Този израз е доста комплексен, но лесно може да покажем, че той ще се опрости, когато $x$ приема за стойност някой от интерполационните възли. Нека разгледаме например случая, когато $x = x_0$:\n",
    "$$\n",
    "N_n'(f; x) = f_{[x_0, x_1]} + f_{[x_0, x_1, x_2]}(x_0 - x_1) + f_{[x_0, x_1, x_2, x_3]}(x_0 - x_1)(x_0 - x_2) + \\dots + f_{[x_0, x_1, \\dots, x_n]}(x_0 - x_1)(x_0 - x_2)\\dots(x_0 - x_{n-1})\n",
    "$$\n",
    "\n",
    "При $\\omega'(x) = 0$ изразът също би се опростил, а това се получава, когато имаме четен брой възли, които са симетрично разположени около точката $x$:\n",
    "$$\n",
    "x - x_i = x_{n-i} - x, i = 0, 1, \\dots, \\frac {n - 1} {2}\n",
    "$$\n",
    "\n",
    "В повечето случай, когато става въпрос за решаване на задачи, най-често се използват частни случаи на тази формула:\n",
    "1. При $n = 1$ и възли $x_0 = a, x_1 = a + h$ получаваме $N'(f; a) = f_{[a, a + h]} = \\frac {f(a + h) - f(a)} {h}$, а допуснатата грешка е $R'(a) = \\frac {f''(\\eta)} {2} h, \\eta \\in (a, a + h)$.\n",
    "2. При $n = 1$ и възли $x_0 = a - h, x_1 = a + h$ получаваме $N'(f; a) = f_{[a - h, a + h]} = \\frac {f(a + h) - f(a - h)} {2h}$, а допуснатата грешка е $R'(a) = -\\frac {f'''(\\xi)} {6} h^2, \\xi \\in (a - h, a + h)$.\n",
    "3. При $n = 2$ и възли $x_0 = a, x_1 = a + h, x_2 = a + 2h$ получаваме $N'(f; a) = f_{[a, a + h]} + f_{[a, a + h, a + 2h]}(-h) = \\frac {-3f(a) + 4f(a + h) -f(a + 2h)} {2h}$, а допуснатата грешка е $R'(a) = -\\frac {f'''(\\eta)} {3} h^2, \\eta \\in (a, a + 2h)$.\n",
    "4. При $n = 2$ и възли $x_0 = a, x_1 = a + h, x_2 = a + 2h$ получаваме $N'(f; a + 2h) = \\frac {f(a) - 4f(a + h) + 3f(a + 2h)} {2h}$, а допуснатата грешка е $R'(a + 2h) = -\\frac {f'''(\\eta)} {3} h^2, \\eta \\in (a, a + 2h)$.\n",
    "5. При $n = 2$ и възли $x_0 = a - h, x_1 = a, x_2 = a + h$ получаваме същата формула от точка 2.\n",
    "\n",
    "#### Доказателство\n",
    "\n",
    "Нека $n = 1$, $x_0 = a$, $x_1 = a + h$, $x = a$\n",
    "$$\n",
    "N_1(f; x) = f_{[x_0]} + f_{[x_0, x_1]}(x - x_0) = f_{[a]} + f_{[a, a + h]}(x - a)\n",
    "$$\n",
    "\n",
    "Когато диференцираме това уравнение спрямо $x$ ще получим това, което записахме по-горе в обобщената формула:\n",
    "$$\n",
    "N_1'(f; x) = f_{[a, a + h]} = \\frac {f(a + h) - f(a)} {h}\n",
    "$$\n",
    "\n",
    "Нека сега да изведем и формулата за грешка:\n",
    "$$\n",
    "\\omega(x) = (x - a)(x - a - h) \\implies \\omega(a) = 0\n",
    "$$\n",
    "$$\n",
    "\\omega'(x) = 2(x - a) - h \\implies \\omega'(a) = -h\n",
    "$$\n",
    "$$\n",
    "|f'(a) - \\frac {f(a + h) - f(a)} {h}| \\le \\frac {M_2} {2} |\\omega'(a)| = \\frac {M_2} {2} h\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Нека $n = 1$, $x_0 = a - h$, $x_1 = a + h$, $x = a$\n",
    "$$\n",
    "N_1(f; x) = f_{[x_0]} + f_{[x_0, x_1]}(x - x_0) = f_{[a - h]} + f_{[a - h, a + h]}(x - a + h)\n",
    "$$\n",
    "\n",
    "Когато диференцираме това уравнение спрямо $x$ ще получим това, което записахме по-горе в обобщената формула:\n",
    "$$\n",
    "N_1'(f; x) = f_{[a - h, a + h]} = \\frac {f(a + h) - f(a - h)} {2h}\n",
    "$$\n",
    "\n",
    "Нека сега да изведем и формулата за грешка:\n",
    "$$\n",
    "\\omega(x) = (x - (a - h))(x - (a + h)) = (x - a)^2 - h^2 \\implies \\omega(a) = -h^2\n",
    "$$\n",
    "$$\n",
    "\\omega'(x) = 2(x - a) \\implies \\omega'(a) = 0\n",
    "$$\n",
    "$$\n",
    "|f'(a) - \\frac {f(a + h) - f(a - h)} {2h}| \\le \\frac {M_3} {3!} |\\omega'(a)| = \\frac {M_3} {6} h^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Доказателството на останалите формули е аналогично."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Формули за пресмятане на втори производни при три равноотстоящи възли\n",
    "Нека приемем, че $x_0 = a, x_1 = a + h, x_2 = a + 2h$. Тогава можем да изведем следните формули:\n",
    "$$\n",
    "f''(a) = \\frac {1} {2h} [f(a) - 2f(a + h) + f(a + 2h)] - hf'''(\\xi) + \\frac {h^2} {6} f^{(4)}(\\eta)\n",
    "$$\n",
    "$$\n",
    "f''(a + h) = \\frac {1} {2h} [f(a) - 2f(a + h) + f(a + 2h)] - \\frac {h^2} {12} f^{(4)}(\\xi)\n",
    "$$\n",
    "$$\n",
    "f''(a) = \\frac {1} {2h} [f(a) - 2f(a + h) + f(a + 2h)] + hf'''(\\xi) - \\frac {h^2} {6} f^{(4)}(\\eta)\n",
    "$$\n",
    "$$\n",
    "\\xi, \\eta \\in [a, a + 2h]\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This cell will contain helper functions used along the way.\n",
    "def extract_single_dimension(data: List[tuple[float, float]], dimension: int) -> List[float]:\n",
    "    return [d[dimension] for d in data]\n",
    "\n",
    "\n",
    "def calculate_divided_differences(data: List[tuple[float, float]]) -> List[List[float]]:\n",
    "    ans = [[] for _ in range(len(data))]\n",
    "    for i in range(len(data)):\n",
    "        ans[0].append(data[i][1])\n",
    "\n",
    "    for k in range(len(data) - 1):\n",
    "        for i in range(len(ans[k]) - 1):\n",
    "            numerator = ans[k][i + 1] - ans[k][i]\n",
    "            denominator = data[i + k + 1][0] - data[i][0]\n",
    "\n",
    "            if numerator == 0 or denominator == 0:\n",
    "                ans[k + 1].append(0)\n",
    "            else:\n",
    "                ans[k + 1].append(numerator / denominator)\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def generate_func_data(x_points: List[float], f: Callable[[float], float]) -> List[tuple[float, float]]:\n",
    "    ans = []\n",
    "\n",
    "    for i in range(len(x_points)):\n",
    "        ans.append((x_points[i], f(x_points[i])))\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def prepare_plot(title: str, x_label: str, y_label: str) -> None:\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "\n",
    "def print_divided_differences(divided_differences: List[List[float]]) -> None:\n",
    "    for i in range(1, len(divided_differences)):\n",
    "        print()\n",
    "        print(f'#{i + 1}')\n",
    "        for j in range(len(divided_differences[i])):\n",
    "            notation = \", \".join([f'x[{p}]' for p in range(j, i + j + 1)])\n",
    "            print(f'f[{notation}] = {divided_differences[i][j]}')\n",
    "\n",
    "\n",
    "def print_interpolation_nodes(data: List[tuple[float, float]]) -> None:\n",
    "    for i in range(len(data)):\n",
    "        print(f'x[{i}] = {data[i][0]}, f(x[{i}]) = {data[i][1]}')\n",
    "\n",
    "\n",
    "def calculate_chebyshev_nodes(n: int, a: float, b: float) -> List[float]:\n",
    "    ans = []\n",
    "\n",
    "    for i in range(n):\n",
    "        current_node = 0.5 * (a + b) + 0.5 * (b - a) * np.cos(((2 * i + 1) / (2 * n)) * np.pi)\n",
    "        ans.append(current_node)\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def interpolate_newton(x: float, data: List[tuple[float, float]], divided_differences: List[List[float]]) -> float:\n",
    "    ans = 0\n",
    "\n",
    "    for i in range(len(divided_differences)):\n",
    "        c = divided_differences[i][0]\n",
    "\n",
    "        for j in range(i):\n",
    "            c *= x - data[j][0]\n",
    "\n",
    "        ans += c\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def visualize_newton_interpolation(name: str, data: List[tuple[float, float]], f: Callable[[float], float] = None,\n",
    "                                   f_deriv: Callable[[float], float] = None, step: float = 0.01,\n",
    "                                   is_verbose: bool = False) \\\n",
    "        -> tuple[Callable[[float], float], Callable[[float], float]]:\n",
    "    if is_verbose:\n",
    "        print_interpolation_nodes(data)\n",
    "\n",
    "    divided_differences = calculate_divided_differences(data)\n",
    "    if is_verbose:\n",
    "        print_divided_differences(divided_differences)\n",
    "\n",
    "    x_coordinates = extract_single_dimension(data, 0)\n",
    "    y_coordinates = extract_single_dimension(data, 1)\n",
    "\n",
    "    def interpolate_in_point(p: float) -> float:\n",
    "        return interpolate_newton(p, data, divided_differences)\n",
    "\n",
    "    def approximate_derivative_in_point(p: float) -> float:\n",
    "        return derivative(interpolate_in_point, p, dx=10 ** -5)\n",
    "\n",
    "    all_points_in_range = np.arange(min(x_coordinates), max(x_coordinates) + step, step)\n",
    "\n",
    "    interpolation_values = [interpolate_in_point(p) for p in all_points_in_range]\n",
    "    interpolation_errors = None\n",
    "\n",
    "    interpolation_deriv_values = [approximate_derivative_in_point(p) for p in all_points_in_range]\n",
    "    interpolation_deriv_errors = None\n",
    "\n",
    "    prepare_plot('Graph of the interpolated function', 'x', 'f(x)')\n",
    "    if f:\n",
    "        f_values = [f(p) for p in all_points_in_range]\n",
    "        interpolation_errors = [v1 - v2 for v1, v2 in zip(f_values, interpolation_values)]\n",
    "        plt.plot(all_points_in_range, f_values, color='orange', linewidth=2, label=\"Original\")\n",
    "\n",
    "    plt.plot(all_points_in_range, interpolation_values, label=\"Interpolated\")\n",
    "    plt.plot(x_coordinates, y_coordinates, marker='o', markersize=3, linewidth=0, color='r',\n",
    "             label=\"Interpolation nodes\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"plots/{name}_interpolated_func.png\")\n",
    "    plt.close()\n",
    "\n",
    "    if interpolation_errors is not None:\n",
    "        prepare_plot('Graph of the interpolation error', 'x', 'R(x)')\n",
    "        plt.plot(all_points_in_range, interpolation_errors, linewidth=1)\n",
    "        plt.savefig(f\"plots/{name}_interpolated_func_error.png\")\n",
    "        plt.close()\n",
    "\n",
    "    prepare_plot('Graph of the interpolated function\\'s derivative', 'x', 'f\\'(x)')\n",
    "    if f_deriv:\n",
    "        f_deriv_values = [f_deriv(p) for p in all_points_in_range]\n",
    "        interpolation_deriv_errors = [v1 - v2 for v1, v2 in zip(f_deriv_values, interpolation_deriv_values)]\n",
    "        plt.plot(all_points_in_range, f_deriv_values, color='orange', linewidth=2, label=\"Original\")\n",
    "\n",
    "    plt.plot(all_points_in_range, interpolation_deriv_values, label=\"Interpolated\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"plots/{name}_interpolated_deriv.png\")\n",
    "    plt.close()\n",
    "\n",
    "    if interpolation_errors is not None:\n",
    "        prepare_plot('Graph of the interpolation derivative error', 'x', 'R\\'(x)')\n",
    "        plt.plot(all_points_in_range, interpolation_deriv_errors, linewidth=1)\n",
    "        plt.savefig(f\"plots/{name}_interpolated_deriv_error.png\")\n",
    "        plt.close()\n",
    "\n",
    "    return interpolate_in_point, approximate_derivative_in_point"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:35.143386100Z",
     "start_time": "2023-08-08T19:31:35.092222300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Примери\n",
    "\n",
    "В следващите редове ще представя няколко примера, които да можем да разгледаме и да анализираме заедно.\n",
    "\n",
    "### Диференциране на таблично зададена функция\n",
    "\n",
    "Нека разгледаме таблично зададената функция $f$:\n",
    "\n",
    "| x   | y   |\n",
    "|-----|-----|\n",
    "| -2  | 29  |\n",
    "| -1  | -6  |\n",
    "| 1   | -4  |\n",
    "| 2   | -3  |\n",
    "| 3   | 14  |\n",
    "\n",
    "Тъй като не знаем нищо повече за тази функция, ние не можем да изчислим грешката на интерполиране, но все пак можем да си построим интерполационния полином и да апроксимираме нейната производна."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0] = -2, f(x[0]) = 29\n",
      "x[1] = -1, f(x[1]) = -6\n",
      "x[2] = 1, f(x[2]) = -4\n",
      "x[3] = 2, f(x[3]) = -3\n",
      "x[4] = 3, f(x[4]) = 14\n",
      "\n",
      "#2\n",
      "f[x[0], x[1]] = -35.0\n",
      "f[x[1], x[2]] = 1.0\n",
      "f[x[2], x[3]] = 1.0\n",
      "f[x[3], x[4]] = 17.0\n",
      "\n",
      "#3\n",
      "f[x[0], x[1], x[2]] = 12.0\n",
      "f[x[1], x[2], x[3]] = 0\n",
      "f[x[2], x[3], x[4]] = 8.0\n",
      "\n",
      "#4\n",
      "f[x[0], x[1], x[2], x[3]] = -3.0\n",
      "f[x[1], x[2], x[3], x[4]] = 2.0\n",
      "\n",
      "#5\n",
      "f[x[0], x[1], x[2], x[3], x[4]] = 1.0\n"
     ]
    }
   ],
   "source": [
    "_ = visualize_newton_interpolation(\"example_1\", [(-2, 29), (-1, -6), (1, -4), (2, -3), (3, 14)], is_verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:35.557776800Z",
     "start_time": "2023-08-08T19:31:35.141384800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/example_1_interpolated_func.png)\n",
    "![Graph of the interpolated function's derivative](./plots/example_1_interpolated_deriv.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Анализиране на грешката при диференциране\n",
    "\n",
    "Да започнем с един изключително лесен пример: $f(x) = sin(x) + cos(x)$. Примерният код ще построи Интерполационен полином на Нютон от 10-та степен, а за интерполационни възли се използват нулите на Полинома на Чебишов в диапазона $[0, 10]$. От получените резултати ще забележим, че грешката при интерполиране на $f(x)$ и грешката при приближаване на $f'(x)$ са по-скоро минимални."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def f2(x: float):\n",
    "    return np.sin(x) + np.cos(x)\n",
    "\n",
    "\n",
    "def f2_deriv(x: float):\n",
    "    return np.cos(x) - np.sin(x)\n",
    "\n",
    "\n",
    "f2_data = generate_func_data(calculate_chebyshev_nodes(11, 0, 10), f2)\n",
    "_ = visualize_newton_interpolation(\"example_2\", f2_data, f2, f2_deriv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:36.389456300Z",
     "start_time": "2023-08-08T19:31:35.597771500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/example_2_interpolated_func.png)\n",
    "![Graph of the interpolation error](./plots/example_2_interpolated_func_error.png)\n",
    "![Graph of the interpolated function's derivative](./plots/example_2_interpolated_deriv.png)\n",
    "![Graph of the interpolation derivative error](./plots/example_2_interpolated_deriv_error.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "А какво би се случило, ако интервала, в който интерполираме съответната функция, е по-голям? Нека да видим!\n",
    "\n",
    "Ще променим интервала, в който са дефинирани интерполационните ни възли на $[0, 100]$ (но забележете, че няма да променим броя на възлите).\n",
    "Разбира се, след като се разгледат графиките по-долу, е очевидно, че точността на построения интерполационен полином е доста по-ниска спрямо това, което наблядавахме по-рано. И докато тогава заключихме, че грешката е по-скоро минимална, то тук виждаме, че тя приема доста по-сериозни стойности."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "f2_data_wide = generate_func_data(calculate_chebyshev_nodes(11, 0, 100), f2)\n",
    "_ = visualize_newton_interpolation(\"example_3\", f2_data_wide, f2, f2_deriv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:38.408119500Z",
     "start_time": "2023-08-08T19:31:36.400587Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/example_3_interpolated_func.png)\n",
    "![Graph of the interpolation error](./plots/example_3_interpolated_func_error.png)\n",
    "![Graph of the interpolated function's derivative](plots/example_3_interpolated_deriv.png)\n",
    "![Graph of the interpolation derivative error](plots/example_3_interpolated_deriv_error.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Следващият пример цели да демонстрира нагледно едно твърдение, което е записано по-горе, а именно, че задачата за числено диференциране не е устойчива. Ще разгледаме следната функция: $f(x) = sin(2x)cos(x) + sin(x)cos(2x)$. Примерният код ще построи Интерполационен полином на Нютон от 15-та степен, а за интерполационни възли се използват нулите на Полинома на Чебишов в диапазона $[0, 10]$. От получените резултати ще забележим, че грешката при интерполиране на $f(x)$ е приемлива, но грешката при приближаване на $f'(x)$ е много по-значителна.\n",
    "\n",
    "Увеличаването на степента на интерполационния полином, който следва да бъде построен, ще намали грешките, но тази неустойчивост при апроксимацията на производната, ще се запази."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def f3(x: float):\n",
    "    return np.sin(2 * x) * np.cos(x) + np.sin(x) * np.cos(2 * x)\n",
    "\n",
    "\n",
    "def f3_deriv(x: float):\n",
    "    return 3 * np.cos(x) * np.cos(2 * x) - 3 * np.sin(x) * np.sin(2 * x)\n",
    "\n",
    "\n",
    "f3_data = generate_func_data(calculate_chebyshev_nodes(16, 0, 10), f3)\n",
    "_ = visualize_newton_interpolation(\"example_4\", f3_data, f3, f3_deriv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:39.270751800Z",
     "start_time": "2023-08-08T19:31:38.409127500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/example_4_interpolated_func.png)\n",
    "![Graph of the interpolation error](./plots/example_4_interpolated_func_error.png)\n",
    "![Graph of the interpolated function's derivative](./plots/example_4_interpolated_deriv.png)\n",
    "![Graph of the interpolation derivative error](./plots/example_4_interpolated_deriv_error.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нека да покажем и резултатите при повишаване на степента на полинома от 15-та на 17-та:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "f3_data_better = generate_func_data(calculate_chebyshev_nodes(18, 0, 10), f3)\n",
    "_ = visualize_newton_interpolation(\"example_5\", f3_data_better, f3, f3_deriv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:40.261935600Z",
     "start_time": "2023-08-08T19:31:39.274746900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/example_5_interpolated_func.png)\n",
    "![Graph of the interpolation error](./plots/example_5_interpolated_func_error.png)\n",
    "![Graph of the interpolated function's derivative](./plots/example_5_interpolated_deriv.png)\n",
    "![Graph of the interpolation derivative error](./plots/example_5_interpolated_deriv_error.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Решаване на задачи\n",
    "\n",
    "Нека разгледаме следната таблично зададена функция:\n",
    "\n",
    "| x   | f(x) |\n",
    "|-----|------|\n",
    "| -1  | 1    |\n",
    "| 1   | 2    |\n",
    "| 2   | 1    |\n",
    "| 3   | 0    |\n",
    "| 4   | 4    |\n",
    "| 5   | 3    |\n",
    "\n",
    "Търсят се приближените стойности на първата производна на зададената функция в точките -1, 1 и 4, като се използват три точки, в които функията е вече известна. Също така трябва да оценим грешката, която се допуска, ако $|f'''(x)| \\le \\frac {1} {10}$ в интервала $(-1, 5)$.\n",
    "\n",
    "#### Решение\n",
    "\n",
    "За да намерим приближената стойност на първата производна в точка -1, можем да използваме следните точки - $(-1, 1, 3)$ или $(-1, 2, 5)$. По-подходящо би било да изберем първата тройка, тъй като при нея стъпката ($h = 2$) е по-малка и това би довело до по-добра точност.\n",
    "\n",
    "$$N'(f; -1) = \\frac {-3f(-1) + 4f(1) -f(3)} {4} = \\frac {-3 * 1 + 4 * 2 - 0} {4} = \\frac {5} {4}$$\n",
    "$$R'(-1) = -4 \\frac {f'''(\\eta)} {3} \\implies |R'(-1)| \\le \\frac {4} {30}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated value is 1.250000000002638\n"
     ]
    }
   ],
   "source": [
    "(_, solve_problem_1_1) = visualize_newton_interpolation(\"problem_1\", [(-1, 1), (1, 2), (3, 0)])\n",
    "print(f\"The approximated value is {solve_problem_1_1(-1)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:40.595543200Z",
     "start_time": "2023-08-08T19:31:40.264932700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/problem_1_interpolated_func.png)\n",
    "![Graph of the interpolated function's derivative](./plots/problem_1_interpolated_deriv.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "За да намерим приближената стойност на първата производна в точка 1, можем да използваме следните точки - $(1, 2, 3)$ или $(1, 3, 5)$. По-подходящо би било да изберем първата тройка, тъй като при нея стъпката ($h = 1$) е по-малка и това би довело до по-добра точност.\n",
    "\n",
    "$$N'(f; 1) = \\frac {-3f(1) + 4f(2) -f(3)} {2} = \\frac {-3 * 2 + 4 * 1 - 0} {2} = -1$$\n",
    "$$R'(1) = -\\frac {f'''(\\eta)} {3} \\implies |R'(1)| \\le \\frac {1} {30}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated value is -1.0000000000065512\n"
     ]
    }
   ],
   "source": [
    "(_, solve_problem_1_2) = visualize_newton_interpolation(\"problem_2\", [(1, 2), (2, 1), (3, 0)])\n",
    "print(f\"The approximated value is {solve_problem_1_2(1)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:40.894785400Z",
     "start_time": "2023-08-08T19:31:40.593545500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/problem_2_interpolated_func.png)\n",
    "![Graph of the interpolated function's derivative](./plots/problem_2_interpolated_deriv.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "За да намерим приближената стойност на първата производна в точка 4, нека разгледаме тройката $(2, 3, 4)$. При нея стъпката $h = 1$.\n",
    "\n",
    "$$N'(f; 4) = \\frac {f(2) - 4f(3) + 3f(4)} {2} = \\frac {1 - 4 * 0 + 3 * 4} {2} = \\frac {13} {2}$$\n",
    "$$R'(4) = -\\frac {f'''(\\eta)} {3} \\implies |R'(4)| \\le \\frac {1} {30}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated value is 6.499999999909355\n"
     ]
    }
   ],
   "source": [
    "(_, solve_problem_1_3) = visualize_newton_interpolation(\"problem_3\", [(2, 1), (3, 0), (4, 4)])\n",
    "print(f\"The approximated value is {solve_problem_1_3(4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:41.205392900Z",
     "start_time": "2023-08-08T19:31:40.892785600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/problem_3_interpolated_func.png)\n",
    "![Graph of the interpolated function's derivative](./plots/problem_3_interpolated_deriv.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "За да намерим приближената стойност на първата производна в точка 4, нека разгледаме тройката $(3, 4, 5)$. При нея стъпката $h = 1$.\n",
    "\n",
    "$$N'(f; 4) = \\frac {f(5) - f(3)} {2} = \\frac {3 - 0} {2} = \\frac {3} {2}$$\n",
    "$$R'(4) = -\\frac {f'''(\\xi)} {6} \\implies |R'(4)| \\le \\frac {1} {60}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated value is 1.4999999999654177\n"
     ]
    }
   ],
   "source": [
    "(_, solve_problem_1_4) = visualize_newton_interpolation(\"problem_4\", [(3, 0), (4, 4), (5, 3)])\n",
    "print(f\"The approximated value is {solve_problem_1_4(4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T19:31:41.535869700Z",
     "start_time": "2023-08-08T19:31:41.208397600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Graph of the interpolated function](./plots/problem_4_interpolated_func.png)\n",
    "![Graph of the interpolated function's derivative](./plots/problem_4_interpolated_deriv.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Използвана литература\n",
    "\n",
    "1. Вежди Хасанов (2019). Ръководство по Числени методи с MATLAB. Шумен. ISBN 978-619-201-310-3\n",
    "2. [Divided differences](https://en.wikipedia.org/wiki/Divided_differences). Wikipedia. Посетен на 2022-12-08 (на английски)\n",
    "3. [Numerical differentiation](https://en.wikipedia.org/wiki/Numerical_differentiation). Wikipedia. Посетен на 2022-12-01 (на английски)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
